# Paper4NLP

## 论文分类
 [TOC]
---

### Attention
1. [SEO, Minjoon, et al. Bidirectional attention flow for machine comprehension. arXiv preprint arXiv:1611.01603, 2016.](https://arxiv.org/pdf/1611.01603)
---
2. [ZADEH, Amir, et al. Multi-attention recurrent network for human communication comprehension. arXiv preprint arXiv:1802.00923, 2018.](https://arxiv.org/pdf/1802.00923)
---
3.[CHEN, Kehai, et al. Syntax-Directed Attention for Neural Machine Translation. arXiv preprint arXiv:1711.04231, 2017.](https://arxiv.org/pdf/1711.04231)

### 词向量表示学习
3.[AutoExtend_ACL2014](https://arxiv.org/pdf/1507.01127)
3.[AutoExtend_ACL2017](https://www.mitpressjournals.org/doi/full/10.1162/COLI_a_00294)
3.[WELLER-DI MARCO, Marion; FRASER, Alexander; IM WALDE, Sabine Schulte. Addressing Problems across Linguistic Levels in SMT: Combining Approaches to Model Morphology, Syntax and Lexical Choice. In: Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers. 2017. p. 625-630.](http://www.aclweb.org/anthology/E17-2099)
3.[YAGHOOBZADEH, Yadollah; SCHÜTZE, Hinrich. Multi-level representations for fine-grained typing of knowledge base entities. arXiv preprint arXiv:1701.02025, 2017.](https://arxiv.org/pdf/1701.02025)
3.[TISSIER, Julien; GRAVIER, Christophe; HABRARD, Amaury. Dict2vec: Learning Word Embeddings using Lexical Dictionaries. In: Conference on Empirical Methods in Natural Language Processing (EMNLP 2017). 2017. p. 254-263.](https://hal-ujm.archives-ouvertes.fr/ujm-01613953/file/emnlp2017.pdf)
3.[PINTER, Yuval; GUTHRIE, Robert; EISENSTEIN, Jacob. Mimicking word embeddings using subword RNNs. arXiv preprint arXiv:1707.06961, 2017.](https://arxiv.org/pdf/1707.06961)
3.[CHIU, Billy, et al. How to train good word embeddings for biomedical NLP. In: Proceedings of the 15th Workshop on Biomedical Natural Language Processing. 2016. p. 166-174.](http://www.aclweb.org/anthology/W16-2922)
3.[XIE, Ruobing, et al. Lexical sememe prediction via word embeddings and matrix factorization. In: Proceedings of the 26th International Joint Conference on Artificial Intelligence. AAAI Press, 2017. p. 4200-4206.](https://www.ijcai.org/proceedings/2017/0587.pdf)
3.[CHE, Zhengping, et al. Exploiting convolutional neural network for risk prediction with medical feature embedding. arXiv preprint arXiv:1701.07474, 2017.](https://arxiv.org/pdf/1701.07474)
3.[YU, Liang-Chih, et al. Refining word embeddings for sentiment analysis. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 534-539.](http://www.aclweb.org/anthology/D17-1056)
3.[FARUQUI, Manaal, et al. Retrofitting word vectors to semantic lexicons. arXiv preprint arXiv:1411.4166, 2014.](https://arxiv.org/pdf/1411.4166)
3.[ABEND, Omri; RAPPOPORT, Ari. The state of the art in semantic representation. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2017. p. 77-89.](http://www.aclweb.org/anthology/P17-1008)
3.[WU, Ledell, et al. StarSpace: Embed All The Things!. arXiv preprint arXiv:1709.03856, 2017.](https://arxiv.org/pdf/1709.03856)
3.[CHEN, Liang-Wei; LEE, Wei-Chun; HWANG, Hsiang-Wei. When Word Embedding Meets Lexical Networks.](https://pdfs.semanticscholar.org/52f9/c705b4303576108cab5a6b22f73f0e7d29af.pdf)

### 对抗GAN
3.[王坤峰, et al. 生成式对抗网络 GAN 的研究进展与展望. 自动化学报, 2017, 43.3: 321-332.](http://html.rhhz.net/ZDHXBZWB/html/20170301.htm)
3.[CHEN, Xinchi, et al. Adversarial multi-criteria learning for chinese word segmentation. arXiv preprint arXiv:1704.07556, 2017.](https://arxiv.org/pdf/1704.07556)
3.[LIU, Pengfei; QIU, Xipeng; HUANG, Xuanjing. Adversarial multi-task learning for text classification. arXiv preprint arXiv:1704.05742, 2017.](https://arxiv.org/pdf/1704.05742)
3.[LI, Zheng, et al. End-to-end adversarial memory network for cross-domain sentiment classification. In: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). 2017. p. 2237.](https://www.ijcai.org/proceedings/2017/0311.https://arxiv.org/pdf/1710.07035pdf)
GUI, Tao, et al. Part-of-speech tagging for twitter with adversarial neural networks. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 2411-2420.3.http://www.aclweb.org/anthology/D17-1256[CRESWELL, Antonia, et al. Generative Adversarial Networks: An Overview. IEEE Signal Processing Magazine, 2018, 35.1: 53-65.](https://arxiv.org/pdf/1710.07035)
3.[GUI, Tao, et al. Part-of-speech tagging for twitter with adversarial neural networks. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 2411-2420.](http://www.aclweb.org/anthology/D17-1256)
3.[KIM, Joo-Kyung, et al. Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 2832-2838.](http://www.aclweb.org/anthology/D17-1302)

### 多任务学习
3.[CRICHTON, Gamal, et al. A neural network multi-task learning approach to biomedical named entity recognition. BMC bioinformatics, 2017, 18.1: 368.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1776-8)
3.[Chen, X., Qiu, X., & Huang, X. (2016). A feature-enriched neural model for joint Chinese word segmentation and part-of-speech tagging. arXiv preprint arXiv:1611.05384.](https://arxiv.org/pdf/1611.05384)
3.[RUDER, Sebastian. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.](https://arxiv.org/pdf/1706.05098)
3.[LONG, Mingsheng, et al. Learning Multiple Tasks with Multilinear Relationship Networks. In: Advances in Neural Information Processing Systems. 2017. p. 1593-1602.](http://papers.nips.cc/paper/6757-learning-multiple-tasks-with-multilinear-relationship-networks.pdf)
3.[AGUILAR, Gustavo, et al. A Multi-task Approach for Named Entity Recognition in Social Media Data. In: Proceedings of the 3rd Workshop on Noisy User-generated Text. 2017. p. 148-153.](http://www.aclweb.org/anthology/W17-4419)

### 关系抽取任务
3.[WU, Yi; BAMMAN, David; RUSSELL, Stuart. Adversarial training for relation extraction. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 1778-1783.](http://www.aclweb.org/anthology/D17-1187)
3.[HUANG, Yi Yao; WANG, William Yang. Deep Residual Learning for Weakly-Supervised Relation Extraction. arXiv preprint arXiv:1707.08866, 2017.](https://arxiv.org/pdf/1707.08866)
3.[HUANG, Yi Yao; WANG, William Yang. Deep Residual Learning for Weakly-Supervised Relation Extraction. arXiv preprint arXiv:1707.08866, 2017.](http://www.aclweb.org/anthology/D17-1182)
3.[HE, Zhengqiu, et al. SEE: Syntax-aware Entity Embedding for Neural Relation Extraction. arXiv preprint arXiv:1801.03603, 2018.](https://arxiv.org/pdf/1801.03603)
3.[GANEA, Octavian-Eugen; HOFMANN, Thomas. Deep Joint Entity Disambiguation with Local Neural Attention. arXiv preprint arXiv:1704.04920, 2017.](https://arxiv.org/pdf/1704.04920)
3.[ADEL, Heike; SCHÜTZE, Hinrich. Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification. arXiv preprint arXiv:1707.07719, 2017.](https://arxiv.org/pdf/1707.07719)
3.[Zeng, W., Lin, Y., Liu, Z., & Sun, M. (2016). Incorporating relation paths in neural relation extraction. arXiv preprint arXiv:1609.07479.](https://arxiv.org/pdf/1609.07479)
3.[TAY, Yi; LUU, Anh Tuan; HUI, Siu Cheung. Learning to Attend via Word-Aspect Associative Fusion for Aspect-based Sentiment Analysis. arXiv preprint arXiv:1712.05403, 2017.](https://arxiv.org/pdf/1712.05403)
3.[Zeng, X., He, S., Liu, K., & Zhao, J. (2018). Large Scaled Relation Extraction with Reinforcement Learning. Relation, 2, 3.](http://159.226.21.68/bitstream/173211/20626/1/Large%20Scaled%20Relation%20Extraction%20with%20Reinforcement%20Learning.pdf)

### 迁移学习
3.[KIM, Joo-Kyung, et al. Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 2832-2838.](http://www.aclweb.org/anthology/D17-1302)
3.[YANG, Zhilin; SALAKHUTDINOV, Ruslan; COHEN, William W. Transfer learning for sequence tagging with hierarchical recurrent networks. arXiv preprint arXiv:1703.06345, 2017.](https://arxiv.org/pdf/1703.06345)
3.[PAN, Sinno Jialin; YANG, Qiang. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 2010, 22.10: 1345-1359.](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf)
3.[PAN, Sinno Jialin, et al. Domain adaptation via transfer component analysis. IEEE Transactions on Neural Networks, 2011, 22.2: 199-210.](http://www.aaai.org/ocs/index.php/IJCAI/IJCAI-09/paper/download/294/962)


### 情感分类
3.[WANG, Bailin; LU, Wei. Learning Latent Opinions for Aspect-level Sentiment Classification. 2018.](http://www.statnlp.org/wp-content/uploads/papers/2018/Learning-Latent/absa.pdf)

### 生物医学实体识别
3.[LUO, Ling, et al. An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition. Bioinformatics, 2017, 1: 8.](https://sci-hub.org.cn/hubdownload?s=https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btx761/23048295/btx761.pdf)
3.[TSAI, Richard Tzong-Han; HSIAO, Yu-Cheng; LAI, Po-Ting. NERChem: adapting NERBio to chemical patents via full-token features and named entity feature with chemical sub-class composition. Database, 2016, 2016.](https://academic.oup.com/database/article/doi/10.1093/database/baw135/2630527)
3.[DAI, Hong-Jie, et al. Enhancing of chemical compound and drug name recognition using representative tag scheme and fine-grained tokenization. Journal of cheminformatics, 2015, 7.S1: S14.
](https://link.springer.com/article/10.1186/1758-2946-7-S1-S14)
3.[HE, Hua, et al. An Insight Extraction System on BioMedical Literature with Deep Neural Networks. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. p. 2691-2701.](http://www.aclweb.org/anthology/D17-1285)
3.[CRICHTON, Gamal, et al. A neural network multi-task learning approach to biomedical named entity recognition. BMC bioinformatics, 2017, 18.1: 368.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1776-8)
3.[李丽双; 郭元凯. 基于 CNN-BLSTM-CRF 模型的生物医学命名实体识别. 中文信息学报, 32.1: 116-122.](http://jcip.cipsc.org.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=2505)
3.[CHOI, Youngduck; CHIU, Chill Yi-I.; SONTAG, David. Learning low-dimensional representations of medical concepts. AMIA Summits on Translational Science Proceedings, 2016, 2016: 41.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001761/)
3.[SMITH, Lawrence H., et al. MedTag: a collection of biomedical annotations. In: Proceedings of the ACL-ISMB workshop on linking biological literature, ontologies and databases: mining biological semantics. Association for Computational Linguistics, 2005. p. 32-37.](https://aclanthology.info/pdf/W/W05/W05-1305.pdf)
3.[ZHAO, Zhehuan, et al. ML-CNN: A novel deep learning based disease named entity recognition architecture. In: Bioinformatics and Biomedicine (BIBM), 2016 IEEE International Conference on. IEEE, 2016. p. 794-794.](https://sci-hub.org.cn/hubdownload?s=http://ieeexplore.ieee.org/abstract/document/7822625/)
3.[KANIMOZHI, U.; MANJULA, D. A CRF Based Machine Learning Approach for Biomedical Named Entity Recognition. In: Recent Trends and Challenges in Computational Models (ICRTCCM), 2017 Second International Conference on. IEEE, 2017. p. 335-342.](https://sci-hub.org.cn/hubdownload?s=http://ieeexplore.ieee.org/abstract/document/8057560/)
3.[REI, Marek; CRICHTON, Gamal KO; PYYSALO, Sampo. Attending to characters in neural sequence labeling models. arXiv preprint arXiv:1611.04361, 2016.
](https://arxiv.org/pdf/1611.04361)
3.[MURUGESAN, Gurusamy, et al. BCC-NER: bidirectional, contextual clues named entity tagger for gene/protein mention recognition. EURASIP Journal on Bioinformatics and Systems Biology, 2017, 2017.1: 7.](https://bsb-eurasipjournals.springeropen.com/articles/10.1186/s13637-017-0060-6)
3.[AL-HEGAMI, Ahmed Sultan; OTHMAN, Ameen Mohammed Farea; BAGASH, Fuad Tarbosh. A biomedical named entity recognition using machine learning classifiers and rich feature set. International Journal of Computer Science and Network Security (IJCSNS), 2017, 17.1: 170.](http://paper.ijcsns.org/07_book/201701/20170126.pdf)
3.[CHO, Hyejin; CHOI, Wonjun; LEE, Hyunju. A method for named entity normalization in biomedical articles: application to diseases and plants. BMC bioinformatics, 2017, 18.1: 451.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1857-8)
3.[LI, Haodi, et al. CNN-based ranking for biomedical entity normalization. BMC bioinformatics, 2017, 18.11: 385.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1805-7)
3.[Disease named entity recognition by combining conditional random fields and bidirectional recurrent neural networks](https://www.researchgate.net/profile/Ruifeng_Xu2/publication/309719928_Disease_named_entity_recognition_by_combining_conditional_random_fields_and_bidirectional_recurrent_neural_networks/links/5825e7c608aeb45b5892c953/Disease-named-entity-recognition-by-combining-conditional-random-fields-and-bidirectional-recurrent-neural-networks.pdf)
3.[PENG, Yifan; LU, Zhiyong. Deep learning for extracting protein-protein interactions from biomedical literature. arXiv preprint arXiv:1706.01556, 2017.](https://arxiv.org/pdf/1706.01556)
3.[LOU, Yinxia, et al. A transition-based joint model for disease named entity recognition and normalization. Bioinformatics, 2017, 33.15: 2363-2371.](https://sci-hub.org.cn/hubdownload?s=https://academic.oup.com/bioinformatics/article/3089942)
3.[PENG, Yifan; LU, Zhiyong. Deep learning for extracting protein-protein interactions from biomedical literature. arXiv preprint arXiv:1706.01556, 2017.](https://arxiv.org/pdf/1706.01556)
3.[LUO, Ling, et al. DUTIR at the BioCreative V. 5. BeCalm Tasks: A BLSTM-CRF Approach for Biomedical Entity Recognition in Patents.](https://www.researchgate.net/profile/Ling_Luo11/publication/317060280_DUTIR_at_the_BioCreative_V5BeCalm_Tasks_A_BLSTM-CRF_Approach_for_Biomedical_Entity_Recognition_in_Patents/links/59258b15458515e3d44581c8/DUTIR-at-the-BioCreative-V5BeCalm-Tasks-A-BLSTM-CRF-Approach-for-Biomedical-Entity-Recognition-in-Patents.pdf)
3.[YADAV, Shweta, et al. Entity Extraction in Biomedical Corpora: An Approach to Evaluate Word Embedding Features with PSO based Feature Selection. In: Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. 2017. p. 1159-1170.](http://www.aclweb.org/anthology/E17-1109)
3.[LI, Yanpeng; LIN, Hongfei; YANG, Zhihao. Incorporating rich background knowledge for gene named entity classification and recognition. BMC bioinformatics, 2009, 10.1: 223.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-10-223)
3.[SAHU, Sunil Kumar; ANAND, Ashish. Recurrent neural network models for disease name recognition using domain invariant features. arXiv preprint arXiv:1606.09371, 2016.](https://arxiv.org/pdf/1606.09371)
3.[ZENG, Donghuo, et al. Enlarging drug dictionary with semi-supervised learning for Drug Entity Recognition. In: Bioinformatics and Biomedicine (BIBM), 2016 IEEE International Conference on. IEEE, 2016. p. 1929-1931.](https://sci-hub.org.cn/hubdownload?s=http://ieeexplore.ieee.org/abstract/document/7822818/)
3.[LYU, Chen, et al. Long short-term memory RNN for biomedical named entity recognition. BMC bioinformatics, 2017, 18.1: 462.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1868-5)
3.[**WEI, Chih-Hsuan; KAO, Hung-Yu; LU, Zhiyong. GNormPlus: an integrative approach for tagging genes, gene families, and protein domains. BioMed research international, 2015, 2015.**](https://www.hindawi.com/journals/bmri/aa/918710/)
3.[SAHU, Sunil Kumar; ANAND, Ashish. Recurrent neural network models for disease name recognition using domain invariant features. arXiv preprint arXiv:1606.09371, 2016.](https://arxiv.org/pdf/1606.09371)
3.[FRIES, Jason, et al. SwellShark: A Generative Model for Biomedical Named Entity Recognition without Labeled Data. arXiv preprint arXiv:1704.06360, 2017.](https://arxiv.org/pdf/1704.06360)

### 实体识别+序列标注
3.[CHIU, Jason PC; NICHOLS, Eric. Named entity recognition with bidirectional LSTM-CNNs. arXiv preprint arXiv:1511.08308, 2015.](https://arxiv.org/pdf/1511.08308)
3.[**REIMERS, Nils; GUREVYCH, Iryna. Optimal hyperparameters for deep lstm-networks for sequence labeling tasks. arXiv preprint arXiv:1707.06799, 2017.**](https://arxiv.org/pdf/1707.06799)
3.[LAMPLE, Guillaume, et al. Neural architectures for named entity recognition. arXiv preprint arXiv:1603.01360, 2016.](https://arxiv.org/pdf/1603.01360)
3.[REI, Marek. Semi-supervised multitask learning for sequence labeling. arXiv preprint arXiv:1704.07156, 2017.](https://arxiv.org/pdf/1704.07156)
3.[PETERS, Matthew E., et al. Semi-supervised sequence tagging with bidirectional language models. arXiv preprint arXiv:1705.00108, 2017.](https://arxiv.org/pdf/1705.00108)
3.[MA, Xuezhe; HOVY, Eduard. End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354, 2016.](https://arxiv.org/pdf/1603.01354)
3.[SUN, Zhiqing; SHEN, Gehui; DENG, Zhihong. A Gap-Based Framework for Chinese Word Segmentation via Very Deep Convolutional Networks. arXiv preprint arXiv:1712.09509, 2017.](https://arxiv.org/pdf/1712.09509)
3.[XU, Mingbin; JIANG, Hui; WATCHARAWITTAYAKUL, Sedtawut. A Local Detection Approach for Named Entity Recognition and Mention Detection. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2017. p. 1237-1247.](http://www.aclweb.org/anthology/P17-1114)
3.[GOYAL, Kartik, et al. A Continuous Relaxation of Beam Search for End-to-end Training of Neural Sequence Models. arXiv preprint arXiv:1708.00111, 2017.](https://arxiv.org/pdf/1708.00111)
3.[LIMSOPATHAM, Nut; COLLIER, Nigel Henry. Bidirectional LSTM for named entity recognition in Twitter messages. 2016.](https://www.repository.cam.ac.uk/bitstream/handle/1810/261962/Limsopatham_and_Collier-2016-WNUT2016-VoR.pdf?sequence=1)
3.[**HUANG, Zhiheng; XU, Wei; YU, Kai. Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv:1508.01991, 2015.
**](https://arxiv.org/pdf/1508.01991)
3.[COLLOBERT, Ronan, et al. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 2011, 12.Aug: 2493-2537.](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()

### 序列模型引入外部知识（词典）
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()

### aaai2018
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()

### DL for NLP 论文
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()

### emnlp论文
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()
3.[]()

### PPT模板
### UMLS论文
3.[]()
3.[]()
3.[]()
3.[]()

### 其他
